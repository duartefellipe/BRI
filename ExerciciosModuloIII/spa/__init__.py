import time, os, re 
from utils import folder_reader, lookup, retrieve_top_k
from utils import word_tokenizer, default_subquery_extractor, default_query_expansion

#_dataset_path = "../../../datasets/spa/corpus-20090418"
# _dataset_path = "../../../Dropbox/Arquivos BRI/Datasets/short plagiarised answers corpus/corpus-20090418"
_dataset_path = "D:/Colecoes de Dados/short plagiarised answers corpus/corpus-20090418"

_queue = []

'''
	mapeia o nome da tarefa de cada documento para o indice do seu texto em _queue
'''
_tn_to_queue = []

'''
	mapeia para cada q quais documentos sÃ£o esperados como resultado (i.e. a resposta correta de cada consulta)
	indice query => id do documento relevantes em _queue
'''
_golden_standard = []

'''
	indexing 
'''
def read_documents():
	global _tn_to_queue
	global _queue
	global _golden_standard
	_queue = []
	_golden_standard = []
	
	folder_to_read  = "/".join([_dataset_path,"source", ])
	_tn_to_queue = os.listdir(folder_to_read)
	index_time, _queue = folder_reader(folder_to_read)
	return index_time, _queue

def preprocess(to_prep, _tokenizer = word_tokenizer):
	start_time = time.time()	
	to_prep = _tokenizer(to_prep)
	return time.time() - start_time, to_prep
	
def express_as(to_express,ir_model):
	if ir_model == "boolean":
		start_time = time.time()	
		to_express = list(set(to_express))
		return time.time() - start_time, to_express
	elif ir_model == "VSM":
		return 0, to_express
	else:
		raise NotImplementedError	
	
def _index(to_index):
	start_time = time.time()	
	_queue.append(to_index)
	return time.time() - start_time

		
'''
	searching
'''
def read_queries():
	global _golden_standard
	_golden_standard = []
	folder_to_read = "/".join([_dataset_path,"light", ])
	
	for qpos, q in enumerate(os.listdir(folder_to_read)):
		q_src_id = _tn_to_queue.index(re.sub("(g.*)_", "orig_",q))
		_golden_standard.append([q_src_id])
	
	return folder_reader(folder_to_read)	
	
def extract_query(to_extract,sq_extractor=default_subquery_extractor, q_expansion = default_query_expansion):
	start_time = time.time()	
	squeries = sq_extractor(to_extract)
	for sqi_pos, sqi in enumerate(squeries):
		squeries[sqi_pos] = q_expansion(sqi)
	
	return time.time() - start_time, squeries

def _search(to_search,how_search):
	return lookup(to_search, _queue,how_search)

def rank_results(query, to_rank, ir_model, k = None):
	return retrieve_top_k(query, to_rank, ir_model, k, _queue)


'''
	evaluation
'''
